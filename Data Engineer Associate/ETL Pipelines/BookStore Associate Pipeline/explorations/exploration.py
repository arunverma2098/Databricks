# Databricks notebook source
# MAGIC %md
# MAGIC ### Example Exploratory Notebook
# MAGIC
# MAGIC Use this notebook to explore the data generated by the pipeline in your preferred programming language.
# MAGIC
# MAGIC **Note**: This notebook is not executed as part of the pipeline.

# COMMAND ----------

spark.sql("USE CATALOG `workspace`")
spark.sql("USE SCHEMA `bookstore_etl_ass`")

# COMMAND ----------

bookstore_dataset_path = "/Volumes/workspace/bookstore_eng_ass/dataset"

# COMMAND ----------

print(bookstore_dataset_path)

# COMMAND ----------

# MAGIC %fs ls /Volumes/workspace/bookstore_eng_ass/dataset/orders-raw

# COMMAND ----------

# MAGIC %sql
# MAGIC select * from workspace.bookstore_etl_ass.orders_raw

# COMMAND ----------

# DBTITLE 1,Cell 5
from pyspark.sql import functions as F
df = (spark.read.table("workspace.bookstore_eng_ass.orders")
        .select(
            F.col("order_id"),
            F.col("customer_id"),
            F.col("quantity"),
            F.col("order_timestamp"))
        .withColumn("order_timestamp", F.from_unixtime(F.col("order_timestamp"),'yyyy-MM-dd HH:mm:ss').cast("timestamp")))

# COMMAND ----------

df = (spark.read.table("workspace.bookstore_eng_ass.customers")
                .selectExpr("customer_id",
                              "profile:first_name as f_name",
                              "profile:last_name as l_name",
                              "profile:address:country as country"))

# COMMAND ----------

orders_refined = (spark.read.table("workspace.bookstore_eng_ass.orders")
                            .select(F.col("order_id"),
                                         F.col("customer_id"), 
                                         F.col("quantity"),
                                         F.col("order_timestamp"))
                            .withColumn("order_timestamp", F.from_unixtime(F.col("order_timestamp"),'yyyy-MM-dd HH:mm:ss').cast("timestamp")))

# COMMAND ----------

customers_refined = (spark.read.table("workspace.bookstore_eng_ass.customers")
                              .selectExpr("customer_id",
                              "profile:first_name as f_name",
                              "profile:last_name as l_name",
                              "profile:address:country as country"))

# COMMAND ----------

orders_cleaned = (orders_refined.join(customers_refined, "customer_id","inner")
                  .select(orders_refined.order_id,
                                           orders_refined.customer_id,
                                           orders_refined.quantity,
                                           orders_refined.order_timestamp,
                                           customers_refined.f_name,
                                           customers_refined.l_name,
                                           customers_refined.country))

# COMMAND ----------

orders_agg = (orders_cleaned.withColumn("order_date", F.date_trunc("DD",F.col("order_timestamp")))
              .filter(F.col("country")== "China")
              .groupBy(F.col("customer_id"), F.col("f_name"), F.col("l_name"), F.col("order_date"))
              .agg(F.sum(F.col("quantity")).alias("books_count")))

# COMMAND ----------

display(orders_cleaned.withColumn("order_date", F.date_trunc('day',F.col("order_timestamp"))))
